{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccf9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb517033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(path):\n",
    "    \"\"\"\n",
    "    Parses the raw FB text files and returns the set of all entities(their machine ids) and relations\n",
    "    \n",
    "    !!!The entities are sorted before assigning them to an index\n",
    "    \n",
    "    Input: path object\n",
    "    \n",
    "    Output: dictionaries of unique integer index to each entity and relation, set of edges for each split\n",
    "    \"\"\"\n",
    "    entities, relations = set(), set()\n",
    "    edge_set = {}\n",
    "    for split in [\"train.txt\", \"valid.txt\", \"test.txt\"]:\n",
    "        with open(os.path.join(path, split), \"r\") as lines:\n",
    "            edges = set()\n",
    "            for line in lines:\n",
    "                lhs, rel, rhs = line.strip().split(\"\\t\")\n",
    "                entities.add(lhs)\n",
    "                entities.add(rhs)\n",
    "                relations.add(rel)\n",
    "                edges.add((lhs,rel,rhs))\n",
    "        edge_set[split] = edges\n",
    "    \n",
    "    ent_id = {k:i for (i,k) in enumerate(sorted(entities))}\n",
    "    rel_id = {k:i for (i,k) in enumerate(sorted(relations))}\n",
    "                \n",
    "    return ent_id, rel_id, edge_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8cafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codebook(path, D_ent, D_rel):\n",
    "    \"\"\"\n",
    "    Generates a codebook for the set of entities and relations by randomly sampling from the unit hyperspheres of dimension\n",
    "    D_ent and D_rel respectively. \n",
    "    \n",
    "    input: path object, entity embedding dimension, relation embedding dimension\n",
    "    \n",
    "    output: dictionary of embeddings for entity and relation set (machine ids are keys for entity), plus output from get_id\n",
    "    \"\"\"\n",
    "    ent_id, rel_id, edge_set = get_sets(path)\n",
    "    \n",
    "    def normal_vec(dim):\n",
    "        vec = np.random.multivariate_normal(np.zeros(dim),np.eye(dim))\n",
    "        return vec/np.linalg.norm(vec)\n",
    "    \n",
    "    def nv_append1(dim):\n",
    "        vec = np.random.multivariate_normal(np.zeros(dim),np.eye(dim))\n",
    "        return np.append(1.,vec/np.linalg.norm(vec))\n",
    "\n",
    "    \n",
    "    ent_code = {k:normal_vec(D_ent) for (i,k) in enumerate(list(ent_id.keys()))}\n",
    "    rel_code = {k:nv_append1(D_rel) for (i,k) in enumerate(list(rel_id.keys()))}\n",
    "    \n",
    "    return ent_id, rel_id, ent_code, rel_code, edge_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96b84720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(path, split, D_ent, D_rel, rel_tensor = False):\n",
    "    \"\"\"\n",
    "    For each entity, generate the embedding of its neighborhood subgraph (all edges involving the entity).\n",
    "    \n",
    "    input: path object, data split, entity embedding dim, relation embedding dim\n",
    "    \"\"\"\n",
    "    ent_id, rel_id, ent_code, rel_code, edge_set = get_codebook(path, D_ent, D_rel)\n",
    "    N_ent = len(ent_id)\n",
    "    \n",
    "    if rel_tensor == True:\n",
    "        embeddings = np.zeros((N_ent,D_ent,D_ent,D_rel+1))\n",
    "    else:\n",
    "        embeddings = np.zeros((N_ent,D_ent,D_ent))\n",
    "    \n",
    "    with open(os.path.join(path, split), \"r\") as lines:\n",
    "        for line in lines:\n",
    "            lhs, rel, rhs = line.strip().split(\"\\t\")\n",
    "            head = ent_code[lhs]\n",
    "            tail = ent_code[rhs]\n",
    "            relation = rel_code[rel]\n",
    "            if rel_tensor == True:\n",
    "                tensor = np.einsum('i,j,k -> ijk',head,tail,relation)\n",
    "            else:\n",
    "                tensor = np.einsum('i,j -> ij', head, tail)\n",
    "            embeddings[ent_id[lhs]] += tensor\n",
    "            embeddings[ent_id[rhs]] += tensor\n",
    "                \n",
    "    return embeddings, ent_id, rel_id, ent_code, rel_code, edge_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73d0d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/shazoop/KG-Embeddings/datasets/FB15K-237'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95dbacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_id,rel_id, edge_set =get_sets(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73fdcc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_total = 0\n",
    "for key in list(edge_set.keys()):\n",
    "    edge_total = edge_total + len(edge_set[key])\n",
    "edge_per_node = math.ceil(edge_total/len(ent_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6193360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, ent_id, rel_id, ent_code, rel_code, edge_set = get_embeddings(path,'train.txt',2*edge_per_node,2*edge_per_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a111cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shazoop/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: \n",
      "    Found GPU%d %s which is of cuda capability %d.%d.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is %d.%d.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn.format(d, name, major, minor, min_arch // 10, min_arch % 10))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(1)\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3f783b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_embeddings = torch.from_numpy(np.stack(list(ent_code.values()),0))\n",
    "rel_embeddings = torch.from_numpy(np.stack(list(rel_code.values()),0))\n",
    "ent_embeddings = ent_embeddings.to(device)\n",
    "rel_embeddings = rel_embeddings.to(device)\n",
    "nbd_embeddings = torch.from_numpy(embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27f8ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tch_projmatrix(ent, ent_embeddings):\n",
    "    '''\n",
    "    Given the code for an entity h, will return a batch of projection matrices for each entity e.\n",
    "    If h,e are vector embeddings, then will compute eh^T for each entity e. Returns the batch of these matrices.\n",
    "    \n",
    "    Input: ent (vector embedding), dictionary of entity vector embeddings\n",
    "    \n",
    "    Output: batch of projection matrices, one for each entity\n",
    "    '''\n",
    "    return torch.einsum('ni,j ->nij',ent_embeddings,ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0c801a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tch_score(edges,ent_embeddings, rel_embeddings, nbd_embeddings, ent_id, rel_id, rel_tensor= False):\n",
    "    '''\n",
    "    Score the proposed relation (h,r,t) by using similarity matching. Assume tail is the variable.\n",
    "    we just use connectivity here and ignore relations when computing similarity\n",
    "    edges is a tuple (mid1, relation, mid2)\n",
    "    '''\n",
    "    #Get the ids/vector embeddings for head, tail, relation. Get nbd embedding for head\n",
    "    head, relation ,tail = edge[0], edge[1], edge[2]\n",
    "    head_ix, tail_ix, relation_ix = ent_id[head], ent_id[tail], rel_id[relation]\n",
    "    head_embed, tail_embed, rel_embed = ent_embeddings[head_ix], ent_embeddings[tail_ix], rel_embeddings[relation_ix]\n",
    "    \n",
    "    if rel_tensor == True:\n",
    "        head_nbd = nbd_embeddings[head_ix,:,:,0] #just use edge connectivity\n",
    "        nbd_embed_norel = nbd_embeddings[:,:,:,0]\n",
    "    else:\n",
    "        head_nbd = nbd_embeddings[head_ix]\n",
    "        nbd_embed_norel = nbd_embeddings\n",
    "    \n",
    "    #Generate the projection matrices for the given head\n",
    "    proj = tch_projmatrix(head_embed, ent_embeddings)\n",
    "    Frob_norm = torch.norm(head_nbd)**2\n",
    "    #Generate the \n",
    "    \n",
    "    #Compute the graph homomorphism coeff\n",
    "    x = torch.einsum('nij,jk -> nik',proj,head_nbd) #left multiply by projection matrix\n",
    "    x = torch.einsum('nij,nkj -> nik',x,proj) #right multiply by transpose\n",
    "    res = torch.bmm(x.permute(0,2,1),nbd_embeddings_norel)\n",
    "    coeff = (1/Frob_norm)*torch.einsum('nii -> n',res) #number of matching edges\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb1af2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = tch_projmatrix(ent_embeddings, head_embed)\n",
    "head_nbd = nbd_embeddings[0]\n",
    "Frob_norm = torch.norm(head_nbd)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "373b7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.einsum('nij,jk -> nik',proj,head_nbd) #left multiply by projection matrix\n",
    "x = torch.einsum('nij,njk -> nik',x,proj.permute(0,2,1)) #right multiply by transpose\n",
    "res = torch.bmm(x.permute(0,2,1),nbd_embeddings)\n",
    "coeff = (1/Frob_norm)*torch.einsum('nii -> n',res) #number of matching edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a641c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = ent_embeddings[0]\n",
    "tail = ent_embeddings[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82d232b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0106, -0.0089,  0.0157,  ..., -0.0141,  0.0116,  0.0064],\n",
       "        [-0.0091,  0.0076, -0.0134,  ...,  0.0121, -0.0099, -0.0055],\n",
       "        [ 0.0039, -0.0032,  0.0057,  ..., -0.0052,  0.0042,  0.0023],\n",
       "        ...,\n",
       "        [ 0.0093, -0.0078,  0.0138,  ..., -0.0124,  0.0101,  0.0056],\n",
       "        [ 0.0068, -0.0057,  0.0101,  ..., -0.0091,  0.0074,  0.0041],\n",
       "        [ 0.0237, -0.0197,  0.0349,  ..., -0.0314,  0.0257,  0.0142]],\n",
       "       device='cuda:1', dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(proj[100],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4dd0b235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0106, -0.0091,  0.0039,  ...,  0.0093,  0.0068,  0.0237],\n",
       "        [-0.0089,  0.0076, -0.0032,  ..., -0.0078, -0.0057, -0.0197],\n",
       "        [ 0.0157, -0.0134,  0.0057,  ...,  0.0138,  0.0101,  0.0349],\n",
       "        ...,\n",
       "        [-0.0141,  0.0121, -0.0052,  ..., -0.0124, -0.0091, -0.0314],\n",
       "        [ 0.0116, -0.0099,  0.0042,  ...,  0.0101,  0.0074,  0.0257],\n",
       "        [ 0.0064, -0.0055,  0.0023,  ...,  0.0056,  0.0041,  0.0142]],\n",
       "       device='cuda:1', dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('i,j->ij',head,tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d49c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_comp = torch.bmm(torch.bmm(proj,nbd_embeddings[:,:,:,0]),proj.permute((0,2,1)))\n",
    "res = torch.bmm(head_comp.permute(0,2,1),nbd_embeddings[:,:,:,0])\n",
    "coeff = (1/Frob_norm)*torch.einsum('nii -> n',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab72db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522cb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(coeff.cpu().numpy(), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016598f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coeff.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c645c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a75ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum('nii->n',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f7756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
